# 项目整体结构

[cloudmusic_spider](#项目整体结构)	// workspace
		│	//  Ctrl + 单击 以跳转
		│
		├─ [database](#database)
		│  ├─ [sql.py](#sql.py)
		│  └─ [utils.py](#utils.py	(database))
		│
		├─ [code](#code)
		│  ├─ [emo](#emo)
		│  │  ├─ [emo_score.py](#emo_score.py)
		│  │  ├─ [neg.txt](#neg.txt)
		│  │  ├─ [pos.txt](#pos.txt)
		│  │  └─ [sentiment.marshal.3](#sentiment.marshal.3)
		│  │
		│  ├─ [playlist](#playlist)
		│  │  ├─ [get_playlist_comments.py](#get_playlist_comments.py)
		│  │  └─ [get_playlist_info.py](#get_playlist_info.py)
		│  │
		│  ├─ [process](#process)
		│  │  ├─ [basic_filiter_xxl.py](#basic_filiter_xxl.py)
		│  │  ├─ [basic_filiter_yk.py](#basic_filiter_yk.py)
		│  │  ├─ [song_rec.py](#song_rec.py)
		│  │  ├─ [upload.py](#upload.py)
		│  │  ├─ [word_count.py](#word_count.py)
		│  │  ├─ [word_cut.py](#word_cut.py)
		│  │  └─ [word_cut_bak.py](#word_cut_bak.py)
		│  │
		│  ├─ [singer](#singer)
		│  │  └─ [get_singer_info.py](#get_singer_info.py)
		│  │
		│  ├─ [song](#song)
		│  │  ├─ [get_song_comments.py](#get_song_comments.py)
		│  │  ├─ [get_song_info.py](#get_song_info.py)
		│  │  ├─ [get_song_lyric.py](#get_song_lyric.py)
        │  │  └─ [get_song_tag.py](#get_song_tag.py)
        │  │
        │  ├─ [spider](#spider)
        │  │  └─ [Singles_chart.py](#Singles_chart.py)	// 爬虫入口
        │  │
        │  ├─ [tools](#tools)
        │  │  ├─ [comment.py](#comment.py)
        │  │  ├─ [file.py](#file.py)
        │  │  ├─ [post_params.py](#post_params.py)
        │  │  ├─ [progressBar.py](#progressBar.py)
        │  │  ├─ [request.py](#request.py)
        │  │  ├─ [sleep.py](#sleep.py)
        │  │  ├─ [stop_words.txt](#stop_words.txt)
        │  │  ├─ [struct.py](#struct.py)
        │  │  └─ [utils.py](#utils.py	(tools))
        │  │
        │  └─ [user](#user)
        │     ├─ [get_user_info.py](#get_user_info.py)
        │     ├─ [get_user_listen_rank.py](#get_user_listen_rank.py)
        │     └─ [get_user_playlist.py](#get_user_playlist.py)
        │
        ├─ [data](#data)	
        │  ├─ [info](#info)
        │  │  ├─ [playlist_info.txt](#playlist_info.txt)
        │  │  ├─ [singer_info.txt](#singer_info.txt)
        │  │  ├─ [song_info.txt](#song_info.txt)
        │  │  └─ [user_info.txt](#user_info.txt)
        │  │
        │  ├─ [playlist_comments](#playlist_comments)
        │  │  ├─ [playlist_3778678.txt](#playlist_3778678.txt)
        │  │  └─ ...
        │  │
        │  ├─ [rec](#rec)
        │  │  ├─ [rec_1904831431.txt](#rec_1904831431.txt)
        │  │  └─ ...
        │  │
        │  ├─ [song_comments](#song_comments)
        │  │  ├─ [song_1904831431.txt](#song_1904831431.txt)
		│  │  └─ ...
		│  │
		│  └─ [store](#store)
		│     ├─ [playlist_comment_emo.txt](#playlist_comment_emo.txt)
		│     └─ [song_comment_emo.txt](#song_comment_emo.txt)
		│
		├─ [README.md](#README.md)
		│
		├─ [使用说明.md](#使用说明.md) 
		│
		└─ [推荐算法.md](#推荐算法.md)

# code

项目代码部分，爬虫入口位于[code/spider/Singles_chart.py](#Singles_chart.py)

## database

### sql.py

说明：从hdfs上拿取并使用SparkRDD计算且整合数据为数据库中表对应的数据格式，存入数据库以供可视化展示调用

函数说明：

- 表14、16、22、23、30为词云表，对应写入数据库的操作在`word_count.py`中，其余均在该文件中写入数据

- 每一个函数对应一个表的数据存入操作，函数名即为表名，诸如userRegion、userAge等函数

- 响应的有辅助函数，辅助进行SparkRDD的计算工作，诸如count_emo、count_style等函数

    

### utils.py	(database)

说明：定义了查看数据库中表结构、表数据，清空表数据的三个二次封装函数，方便进行测试工作

函数功能：

- showTable()函数：查看指定表

- selectAll()函数：查看指定表中所有数据

- deleteAll()函数：清空指定表中所有数据

    

## emo

本部分负责训练snownlp情感分析模型&计算各类emo指数

### emo_score.py

该文件负责借助snownlp分析歌词、评论、用户个性签名等一系列可能体现情感的语料，从而计算各类emo指数，具体如下：

- 一首歌的歌词emo指数
- 所有歌曲的歌词emo指数
- 单个评论文件的emo指数
- 所有评论文件的emo指数
- 单个歌曲的emo指数
- 所有歌曲的emo指数
- 单个用户的emo指数
- 所有用户的emo指数
- 单个歌手的emo指数
- 所有歌手的emo指数
- 单个歌单的emo指数
- 所有歌单的emo指数

以上各类emo指数采用Spark进行分析，其中歌单和单曲的emo指数先暂存于本地的[data/store](#store)文件夹下，随后上传至hdfs中，其余信息均直接存入hdfs内。

### neg.txt

用于训练snownlp情感分析模型的消极语料库，其中包含的用户评价emo程度较高

### pos.txt

用于训练snownlp情感分析模型的积极语料库，其中包含的用户评价emo程度较低

### sentiment.marshal.3

通过以上两个语料库训练得到的情感分析模型，可直接使用

在使用中，需要注意修改"**your_path_to_python**\Lib\site-packages\snownlp\sentiment\__init__.py"文件中的：

```python
data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                          'sentiment.marshal')
```

==》'sentiment.marshal'改为本机上到本文件的绝对路径，但**不需要添加后缀".3"**，例如：

```python
data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                          'E:/sentiment.marshal')
```



## playlist

负责歌单相关的信息爬取

### get_playlist_comments.py

负责爬取某一歌单下的评论信息，并返回参与评论的用户id列表以及评论总数

在运行过程中调用[tools](#tools)中的[comment.py](#comment.py)内的工具方法从json中提取相关信息，具体细节可跳转查看[Ctrl + 单击]

使用的歌单评论接口为：

```python
url = f'https://music.163.com/api/v1/resource/comments/A_PL_0_{playlistid}?limit=20&offset={page}'
```

数据爬取结束后暂存于本地的[data/playlist_comments](#playlist_comments)文件夹下，详细信息可跳转查看。

### get_playlist_info.py

负责爬取某一歌单的详细信息，并返回上榜歌曲的id列表。

使用的歌单详情接口为：

```python
url = f'https://music.163.com/api/v1/playlist/detail?id={playlistid}'
```

爬取的信息包括:

- 歌单ID
- 歌单名称
- 播放量
- 收藏量
- 歌单描述
- 歌单标签
- 创建者ID
- 上榜歌曲ID列表
- 歌单收录音乐的数量
- 评论数

以上数据爬取结束后暂存于本地的[data/info/playlist_info.txt](#playlist_info.txt)中，详细信息可跳转查看。

## process

### basic_filiter_xxl.py

说明：对data目录下的原始数据进行清洗（方法一），存放在hdfs上的basic_data目录下，上下两个清洗脚本的区别体现在清洗评论文件，方法一是并行处理，适用于对每个文件操作较为简单的情况；方法二是遍历处理，适用于文件数量较少，单文件操作相对复杂的情况。

custom_function()函数：对单个评论文件对象进行清洗的操作

其他函数的功能与下面的`basic_filiter_yk.py`操作相同。



### basic_filiter_yk.py

说明：对data目录下的原始数据进行清洗（方法二），存放在hdfs上的basic_data目录下

函数功能：

- lyric_filter()函数：对歌词使用正则表达式进行过滤，过滤时间戳`[00:00.00]`和歌曲创作信息`作词 : 周杰伦`

- new_dir()函数：在hdfs上创建basic_data目录存放清洗后的数据，新建info、playlist_comments、song_comments目录分别存放信息文件、所有歌单评论文件、所有歌曲评论文件
- singer_info_filter()函数：对`data/info/singer_info.txt`文件中的歌手信息进行过滤，按照歌手ID去重，去除属性数不为5的记录
- playlist_info_filter()函数：对`data/info/playlist_info.txt`文件中的歌单信息进行过滤，按照歌单ID去重，去除属性数不为10的记录
- user_info_filter()函数：对`data/info/user_info.txt`文件中的用户信息进行过滤，按照用户ID去重，去除属性数不为11的记录，去除年龄不在指定范围内的记录
- song_info_filter()函数：对`data/info/song_info.txt`文件中的歌曲信息进行过滤，按照歌曲ID去重，去除属性数不为8的记录，去除歌曲歌词为空、并对第五列的歌词进行清洗操作
- comment_filter()函数：对`data/playlist_comments/`和`data/song_comments`目录下的所有评论文件进行清洗操作，由于一个用户可以连续发多条评论，所以评论不去重，去除属性数不为6和评论内容为空的记录

其中，对所有的评论文件进行清洗，遍历每一个评论文件生成的rdd执行上述清洗评论文件的操作。



### song_rec.py

负责相似歌曲推荐算法的实现，主要是结合歌曲本身和用户画像，从爬取的歌曲库中筛选出相似歌曲。

算法具体思路详见文档 	[推荐算法.md](推荐算法.md)	[Ctrl + 单击以跳转]

### upload.py

说明：上传本地爬取的原始数据到hdfs上的`/data/`目录下，前期没有发现hdfs的`hdfs -fs get`命令不仅可以上传文件还可以上传目录，但是该文件的上传速度和命令差不多，并且增加了进度条，可以实时看到上传速度。



### word_count.py

说明：对`word_cut.py`文件分词后的`/cut_data/`目录下的数据进行词频统计，生成词云.

函数功能：

- extract_words()函数：提取评论中的地区和单词。
- transform()函数：统计完每个地区的高频词汇后整理为一个元组(region, words, frequences)。
- province_word_count()函数：统计每个地区评论中的词频，先整合所有的评论为一个rdd，然后按照地区统计高频词汇，并且进行排序操作。
- playlist_word_count()函数：统计每个歌单评论中的词频。
- count_lyric()函数 + song_word_count()函数：统计每一首歌的歌词的词云。
- song_comment_wordcount()函数：统计每首歌的评论区词云。
- singer_word_count()函数：统计每个歌手创建歌曲时的高频词汇，需要先获取每个歌手对应创作的歌曲，然后结合所有其创作的歌曲，获得该歌手创作时高频的词汇。

根据以上函数的功能，可以实现地区评论词云、歌单评论词云、歌词词云、歌曲评论词云、歌手创作词云



### word_cut.py

说明：对用户的个人简介、歌曲的歌词、评论进行分词（方法一），并且存入新创建的`/cut_data/`目录下。

函数功能：

- stopwordslist()函数：手动在`/tools/stop_words.txt`中增加停用词、读取停用词，并且转换为集合，加快后续查找速度；	  
- jieba_addwords()函数：手动增加分词；
- depart()函数：对输入句子进行分词

以上三个函数，调用jieba分词库，实现分词功能。

- signature_cut()函数：对用户的个人简介进行分词
- lyric_cut()函数：对歌曲的歌词进行分词
- comment_cut()函数：对评论进行分词

其中，该函数对所有评论文件的清洗操作是并行进行的。



### word_cut_bak.py

说明：对用户的个人简介、歌曲的歌词、评论进行分词（方法二），并且存入新创建的`/cut_data/`目录下。

与方法一的区别是这个方法的处理方式是遍历所有评论文件的rdd进行分词。



## singer

负责歌手相关信息的爬取

### get_singer_info.py

负责爬取某一歌手的详细信息

使用的歌手详情接口为：

```python
url = f'http://music.163.com/api/artist/{singer_id}'
```

爬取的信息包括:

- 歌手ID
- 歌手名称
- [歌手用户ID]
- [歌手粉丝]
- 热门歌曲ID列表

ps : 其中[ ]表示可选内容 (有些歌手虽有歌手页面，但未开通个人主页，无法获取这些信息)

以上数据爬取结束后暂存于本地的[data/info/singer_info.txt](#singer_info.txt)中，详细信息可跳转查看。

## song

负责单曲相关信息的爬取

### get_song_comments.py

负责爬取某一单曲下评论的详细信息，并返回参与评论的用户id列表以及评论总数

在运行过程中调用[tools](#tools)中的[comment.py](#comment.py)内的工具方法从json中提取相关信息，具体细节可跳转查看[Ctrl + 单击]

使用的单曲评论接口为：

```python
url = f'https://music.163.com/api/v1/resource/comments/A_PL_0_{playlistid}?limit=20&offset={page}'
```

数据爬取结束后暂存于本地的[data/song_comments](#song_comments)文件夹下，详细信息可跳转查看。

### get_song_info.py

负责爬取某一单曲的详细信息，并返回歌手ID

使用的单曲详情接口为：

```python
url = f'https://music.163.com/api/song/detail/?id={songid}&ids=[{songid}]'
```

爬取的信息包括:

- 歌曲ID
- 歌曲名称
- 歌手ID
- 歌手名
- 所属专辑
- 歌词  [调用[get_song_lyric.py](#get_song_lyric.py) 实现]
- 评论数
- 歌曲标签  [调用[get_song_tag.py](#get_song_tag.py) 实现]

以上数据爬取结束后暂存于本地的[data/info/song_info.txt](#playlist_info.txt)中，详细信息可跳转查看。

### get_song_lyric.py

负责爬取某一单曲的歌词，并将其返回至[get_song_info.py](#get_song_info.py)

使用的歌词获取接口为：

```python
url = f'https://music.163.com/api/song/lyric?id={songid}&lv=1&kv=1&tv=-1'
```

### get_song_tag.py

负责提取某一单曲的标签，并将其返回至[get_song_info.py](#get_song_info.py)

由于网易云并未给某一首歌曲添加标签[亦可能未向用户开放展示/我们未发现]，故而我们选择提取包含这首歌曲的歌单的标签，取其并集作为这首歌的标签。

主要步骤如下：

1. 获取包含这首单曲的歌单列表：

   使用的接口为：

   ```python
   url = f"https://music.163.com/song?id={song_id}"
   ```

   ​		该接口返回结果的形式为HTML，借助lxml库中的HTML对其进行转换，并利用XPATH技术快速提取包含这首单曲的歌单列表

   ​		其中，定位包含这首单曲的歌单列表的XPATH路径为：

   ```python
   html.xpath("//div[@class='info']//@data-res-id")
   ```

   

2. 获取指定歌单的标签：

   使用的接口为：

   ```python
   url = f"https://music.163.com/playlist?id={playlistid}"
   ```

   ​		类似的，该接口的返回显示同样是HTML，利用XPATH可快速提取该歌单附带的标签属性

   ​		其中，定位歌单标签的XPATH路径为：

   ```python
   html.xpath("//div[@class='tags f-cb']//i/text()")
   ```

## spider

存放爬虫的入口程序Singles_chart.py

### Singles_chart.py

**爬虫程序入口**

#### 多进程

利用multiprocessing多进程库中的：

- Process进程	用于构建分析歌单的一级子进程
- Pool进程池	用于构建分析单曲/用户的二级子进程
- Manager[主要使用其中的Queue队列]	用于配合Pool完成多进程中返回值的传递
- Semaphore信号量	用于限制Process并发度

实现了爬虫程序的并行化

文件开头处封装了进程并发数量限制接口：

```python
# 进程数量限制
def limit_list():	#一级子进程
    return 4
def limit_track():	#二级子进程
    return 4
def limit_user():	#二级子进程
    return 4
```

ps:请根据电脑性能和网络情况，调整合适的进程数限制。限制设置不当时，windows系统可能会因为CPU过载而崩溃，推荐使用linux运行。

#### 具体逻辑

- main函数入口

  从[code/tools/struct](#code/tools/struct)中取出带爬取的榜单字典`Music_charts`

  对于其中的每一个榜单，为其生成一个一级子进程，各自调用`analist`函数

  一级子进程的并发度由Semaphore信号量进行控制

  每次生成进程后，设置等待时间，防止CPU短时内过载[linux似乎无此问题]

- analist函数

  分析某一榜单所有相关信息的接口

  功能包含：

  1. 进入时占用Semaphore信号量
  2. 调用[get_playlist_comments](#get_playlist_comments.py)爬取歌单评论
  3. 调用[get_playlist_info](#get_playlist_info.py)爬取歌单基本信息
  4. 利用进程池并发调用`anasong()`爬取与单曲相关的内容
  5. 等待单曲分析进程结束，从Manager().Queue()中取得待分析的用户id列表
  6. 利用进程池并发调用`anauser()`爬取与用户相关的内容
  7. 退出时释放Semaphore信号量


- anasong函数

  分析某一单曲所有相关信息的接口

  功能包括：

  1. 调用[get_song_comments](#get_song_comments.py)爬取单曲评论
  2. 调用[get_song_info](#get_song_info.py)爬取单曲基本信息
  3. 调用[get_singer_info](#get_singer_info.py)爬取歌手相关信息
  4. 将上层函数需要的返回值存入Manager().Queue()

- anauser函数

  分析某一用户所有相关信息的接口

  功能包括：

  1. 调用[get_user_info](#get_user_info.py)爬取用户相关信息

## tools

### comment.py

说明：处理请求获得的json格式的一页评论

函数说明：

- hotcomments()函数：从第一页的评论数据中提取出所有热评信息（评论用户ID、评论内容、评论地区等），并返回评论者的用户ID
- comments()函数：从评论数据中提取出所有评论信息（评论用户ID、评论内容、评论地区等），并返回评论者的用户ID

### file.py

说明：定义了一些与文件相关操作

函数说明：

- json2str()函数：将json格式的值列表转换为逗号分割的字符串

- add_header()函数：向指定文件添加文件头

- save_csv()函数：将json格式值数据写入csv文件

- cleardir()函数：清空非空目录

    

### post_params.py

说明：定义网易云音乐加密获取post参数的函数

函数功能：

- generate_random_strs()函数：生成指定长度的随机字符串
- AESencrypt()函数：AES加密过程
- RSAencrypt()函数：RSA加密
- get_params()函数：根据页号获取post参数：两次AES加密生成encText，再进行RSA加密生成encSecKey
- get_params_id()函数：根据id获取post参数：两次AES加密生成encText，再进行RSA加密生成encSecKey

### progressBar.py

进度条

### request.py

说明：二次封装了requests库的接口，将请求得到的数据转换为json格式并且增加了请求异常时的处理

函数功能：

- get()函数：对requests库的get()二次封装
- post()函数：对requests库的post()二次封装

### sleep.py

主要用于进程/网络拥塞控制

根据提供的平均休眠时间mu，执行在[0.5×mu , 1.5×mu]内服从正态分布的休眠时间

### stop_words.txt

说明：停用词表，用于定义分词时的停用词，一行为一个停用词

### struct.py

说明：定义一些常用的结构体，直接在其他文件被使用

结构体作用：

- headers：伪造请求头
- User_Agent：用户代理池，get_header()获取其中的一个随机用户代理

- city_dic：城市字典，因为爬取用户基本信息时，得到的是省份的ID，与省份有固定的对应关系，所以将映射关系记录在这里
- Music_charts：需要爬取的单曲排行榜和对应的歌单id
- file_headers：文件头，记录了song_info、singer_info、playlist_info、user_info信息文件和评论文件的属性名
- file_info_paths：信息文件的路径，记录了song_info、singer_info、playlist_info、user_info信息文件的路径

### utils.py	(tools)

说明：定义了一些基本的转换操作

函数功能：

- list2str()函数：将列表转换为空格间隔的字符串
- user_age()函数：根据生日时间戳(ms)，计算出年龄。爬取用户的基本信息时，只能获取用户的生日时间戳，需要根据当前时间戳计算出年龄
- timestamp2date()函数：将时间戳(ms)转换为日期与时间，但是评论的时间最终没有采用，该函数保留

## user

负责用户相关信息的爬取

### get_user_info.py

负责爬取某一用户的详细信息

使用的用户详情接口为：

```python
url = f'https://music.163.com/api/v1/user/detail/{user_id}'
```

爬取的信息包括:

- 用户ID
- 用户名
- 性别
- 年龄
- 省份地区
- 个人介绍
- 累计听歌总数
- 用户听歌排行	[调用[get_user_listen_rank.py](#get_user_listen_rank.py)实现]
- 用户创建和收藏的歌单	[调用[get_user_playlist.py](#get_user_playlist.py)实现]
- 听歌排行内歌曲的评论和基本信息	[调用[get_song_comments.py](#get_song_comments.py)及[get_song_info.py](#get_song_info.py)实现]

以上数据爬取结束后暂存于本地的[data/info/user_info.txt](#user_info.txt)中，详细信息可跳转查看。

### get_user_listen_rank.py

负责爬取某一用户的听歌排行，并返回单曲ID列表至[get_user_info](#get_user_info.py)

使用的用户听歌排行接口为：

```python
url='https://music.163.com/weapi/v1/play/record?csrf_token='
```

注意：此处需要调用[post_params.py](#post_params.py)内的方法进行加密，详情可跳转查看

### get_user_playlist.py

负责爬取某一用户的创建/收藏的歌单信息，并返回歌单ID列表至[get_user_info](#get_user_info.py)

使用的用户歌单接口为：

```python
url = f'https://music.163.com/api/user/playlist/?offset=0&limit=200&uid={user_id}'
```

# data

项目数据部分，用于存储爬取到的数据

## info

项目数据的信息汇总部分

### playlist_info.txt

项目数据歌单信息的汇总，每行存放一个歌单的信息，包含：

- 歌单ID

- 歌单名字

- 播放量

- 收藏数

- 歌单描述（如果该歌单没有歌单描述，该字段设置为：null）

- 歌单标签（如果该歌单没有歌单标签，该字段设置为：null）

- 创建者ID

- 收录歌曲数量

- 歌曲ID列表（只包含该歌单的前十首歌曲的歌曲ID，之间用空格分隔）

- 评论量

每个字段之间用分隔符" @#$#@ "分隔。

### singer_info.txt

项目数据中歌手信息的汇总，每行存放一个歌手的信息，包含：

- 歌手ID

- 歌手名称

- 歌手用户ID（如果该歌手没有用户ID则为：null，即不存在歌手个人主页）

- 歌手的粉丝数量（如果歌手用户ID为null时同样为：null）

- 该歌手的热门歌曲ID列表（取前十首热门歌曲歌曲ID，之间用空格分隔开）

每个字段之间用分隔符" @#$#@ "分隔。

### song_info.txt

项目数据中的歌曲信息的汇总，每行存放一首歌的信息，包含：

- 歌曲ID
- 歌曲名字
- 歌手ID
- 歌手名字（如果存在多个歌手，只取第一个）
- 歌曲所属专辑
- 歌词（如果获取不到歌词或者歌词为空就为：null）
- 评论数量
- 歌曲风格标签（如果没有歌曲风格标签则为：null）

每个字段之间用分隔符" @#$#@ "分隔。

### user_info.txt

项目中的用户歌曲信息汇总，每行存放一个用户的信息，包含：

- 用户ID
- 用户名
- 性别
- 年龄
- 用户所属省份
- 个人介绍
- 累计听歌数
- 总听歌排行前五首歌歌曲ID列表（以空格分隔，如果不够五首就取全部，如果没有或者无法访问就为：null）
- 最近一周听歌排行前五首歌歌曲ID列表（以空格分隔，如果不够五首就取全部，如果没有或者无法访问就为：null）
- 创建的歌单的ID列表（以空格隔开，如果没有或无法访问就为：null）
- 收藏的歌单的ID列表（以空格隔开，如果没有或无法访问就为：null）

每个字段之间用分隔符" @#$#@ "分隔。

## playlist_comments

项目数据中的歌单评论部分，分文件存放各个歌单的评论的基本信息

### playlist_3778678.txt

项目数据中的歌单的评论，命名中的“3778678”一段是根据歌单ID进行拼接，代表歌单ID为“3778678”的歌单的评论详细信息。包含：

- 发表评论的用户ID
- 发表评论的用户名
- 评论ID
- 评论内容
- 评论发表时间
- 评论点赞数
- 评论发表省份

每个字段之间用分隔符" @#$#@ "分隔。

## rec

项目数据中的相似歌曲推荐部分，分文件存放各歌曲的推荐歌曲的基本信息

### rec_1904831431.txt

项目数据中的相似歌曲推荐算法结果，命名中的“1904831431”一段是根据歌曲ID进行拼接，代表歌曲ID为“1904831431”的歌曲的相似歌曲信息。包含：

- 相似歌曲的ID
- 相似歌曲的名称
- 相似歌曲的emo指数
- 相似歌曲的标签

每个字段之间用分隔符" @#$#@ "分隔。

## song_comments

项目数据中的歌曲评论部分，分文件存放各歌曲的评论的基本信息

### song_1904831431.txt

项目数据中的歌曲的评论，命名中的“1904831431”一段是根据歌曲ID进行拼接，代表歌曲ID为“1904831431”的歌曲的评论详细信息。包含：

- 发表评论的用户ID
- 发表评论的用户名
- 评论ID
- 评论内容
- 评论发表时间
- 评论点赞数
- 评论发表省份

每个字段之间用分隔符" @#$#@ "分隔。

## store

用于存放项目数据经过过滤清洗并使用算法给对应的歌单评论和歌曲评论进行评分后的数据，方便后续算法查询emo指数。

### playlist_comment_emo.txt

存放歌单和对应的emo指数，只包含两个字段：

- 歌单ID
- 歌单综合emo指数

两个字段之间用分隔符" @#$#@ "分隔。

### song_comment_emo.txt

存放歌曲和对应的emo指数，只包含两个字段：

- 歌曲ID
- 歌曲综合emo指数

两个字段之间用分隔符" @#$#@ "分隔。

# README.md

项目说明文档

包含：

- 项目题目
- 研究主要内容
- 主要技术指标

# 使用说明.md

本文档

# 推荐算法.md

本项目中相似歌曲推荐算法的介绍文档
